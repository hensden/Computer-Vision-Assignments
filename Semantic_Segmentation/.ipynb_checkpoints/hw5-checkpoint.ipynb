{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/hensden/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/hensden/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/hensden/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DATASET CLASS\n",
    "class KittiDataSet(Dataset):\n",
    "    def __init__(self, img_fnames, lab_fnames):\n",
    "        self.imgs = img_fnames\n",
    "        self.labs = lab_fnames\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_file, y_file = self.imgs[idx], self.labs[idx]\n",
    "        X = self.read_img(X_file)\n",
    "        y = self.read_img(y_file)\n",
    "        return X.transpose(2,0,1), y\n",
    "        \n",
    "    def read_img(self, img):\n",
    "        image = Image.open(img)\n",
    "        image = image.resize((1242,375), Image.ANTIALIAS)\n",
    "        return np.asarray(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDER FILENAMES\n",
    "datapath, labelpath = './training/image_2/','./training/semantic/'\n",
    "fnames = [datapath + i for i in sorted(os.listdir(datapath))]\n",
    "training_imgs, validation_imgs, test_imgs =\\\n",
    "fnames[:140], fnames[140:170], fnames[170:]\n",
    "fnames2 = [labelpath + i for i in sorted(os.listdir(labelpath))]\n",
    "training_labs, validation_labs, test_labs =\\\n",
    "fnames2[:140], fnames2[140:170], fnames2[170:]\n",
    "\n",
    "# DEFINE DATASET OBJECTS\n",
    "training_set = KittiDataSet(training_imgs, training_labs)\n",
    "validation_set = KittiDataSet(validation_imgs, validation_labs)\n",
    "test_set = KittiDataSet(test_imgs, test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEED DATASET PARAMS TO DATALOADER\n",
    "params = {'batch_size': 1,'shuffle': True,'num_workers': 1}        \n",
    "train_loader = DataLoader(training_set, **params)\n",
    "val_loader   = DataLoader(validation_set, **params)\n",
    "test_loader  = DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN32:\n",
    "class FCN32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN32, self).__init__()\n",
    "        vgg_model = vgg16(pretrained=True)\n",
    "        self.features = vgg_model.features\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, kernel_size=(7,7)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(4096, 4096, kernel_size=(1,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(4096, 34, kernel_size=(1,1))\n",
    "        )\n",
    "        self.deconv9 = nn.ConvTranspose2d(34, 34, (247, 250), 32)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        y = self.features(batch)\n",
    "        y = self.conv6(y)\n",
    "        y = self.conv7(y)\n",
    "        y = self.conv8(y)\n",
    "        y = self.deconv9(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN32(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv7): Sequential(\n",
      "    (0): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv8): Sequential(\n",
      "    (0): Conv2d(4096, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (deconv9): ConvTranspose2d(34, 34, kernel_size=(247, 250), stride=(32, 32))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FCN32()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ce_loss(y, gt):\n",
    "    return F.cross_entropy(y, gt)\n",
    "\n",
    "def get_pixel_accuracy(y, gt):\n",
    "    ious = []\n",
    "    y_hat = y.argmax(axis=1)\n",
    "    for c in range(34):\n",
    "        TP = float(((y_hat==c)&(gt==c)).type(torch.int).sum())\n",
    "        FN = float(((y_hat!=c)&(gt==c)).type(torch.int).sum())\n",
    "        FP = float(((y_hat==c)&(gt!=c)).type(torch.int).sum())\n",
    "        ious.append(TP/(1+TP+FP+FN))\n",
    "    return np.asarray(ious)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "lr = 0.001\n",
    "rms = 0.99\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hensden/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py:63: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n",
      "/home/hensden/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py:63: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,\n",
      "Training logger: {'loss': 2.231139402730124, 'miou': 0.03487132173784461, 'ious': array([3.29513133e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       8.55884348e-04, 0.00000000e+00, 1.00851843e-04, 4.54172074e-01,\n",
      "       1.41294815e-03, 1.56177860e-04, 4.64010574e-04, 7.67820043e-03,\n",
      "       9.55164439e-05, 6.46529816e-04, 1.30659635e-04, 1.82249446e-04,\n",
      "       0.00000000e+00, 1.01080229e-03, 5.04162139e-06, 3.41901004e-04,\n",
      "       3.30868080e-04, 3.65197319e-01, 4.83024627e-02, 2.24967701e-01,\n",
      "       8.67925216e-05, 2.43131447e-05, 7.89936335e-02, 1.99117424e-04,\n",
      "       1.30511089e-04, 0.00000000e+00, 2.48447205e-06, 3.55965188e-05,\n",
      "       0.00000000e+00, 6.83404619e-05])}, \n",
      "Validation logger: {'loss': 2.166450262069702, 'miou': 0.033374722527458635, 'ious': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.50327437, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.36735131, 0.068598  , 0.185712  , 0.        ,\n",
      "       0.        , 0.00980488, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hensden/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py:63: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e6484070214c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# accuracy functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pixel_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mmiou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mious\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-07862638d8ec>\u001b[0m in \u001b[0;36mget_pixel_accuracy\u001b[0;34m(y, gt)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mTP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mFP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_history = []\n",
    "train_history = []\n",
    "best_val = +float('inf')\n",
    "for epoch in range(epochs):\n",
    "    trl = []\n",
    "    tra = []\n",
    "    trp = []\n",
    "    for chunk in train_loader:\n",
    "        # unpack data to device\n",
    "        data, label = chunk\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        label = label.type(torch.LongTensor)\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # feed forward\n",
    "        output = model(data)\n",
    "        # loss backprop\n",
    "        loss = get_ce_loss(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # accuracy functions\n",
    "        ious = get_pixel_accuracy(output, label)\n",
    "        miou = ious.mean()\n",
    "        trl.append(float(loss))\n",
    "        tra.append(miou)\n",
    "        trp.append(ious)\n",
    "    tr_loss = np.asarray(trl).mean()\n",
    "    tr_miou = np.asarray(tra).mean()\n",
    "    tr_ious = np.asarray(trp).mean(axis=0)\n",
    "    tr_dict = {'loss':tr_loss, 'miou':tr_miou, 'ious':tr_ious}\n",
    "    train_history.append(tr_dict)\n",
    "    \n",
    "    trl = []\n",
    "    tra = []\n",
    "    trp = []\n",
    "    for chunk in val_loader:\n",
    "        data, label = chunk\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        label = label.type(torch.LongTensor)\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # feed forward\n",
    "        output = model(data)\n",
    "        ious = get_pixel_accuracy(output, label)\n",
    "        miou = ious.mean()\n",
    "        trl.append(float(loss))\n",
    "        tra.append(miou)\n",
    "        trp.append(ious)\n",
    "    tr_loss = np.asarray(trl).mean()\n",
    "    tr_miou = np.asarray(tra).mean()\n",
    "    tr_ious = np.asarray(trp).mean(axis=0)\n",
    "    val_dict = {'loss':tr_loss, 'miou':tr_miou, 'ious':tr_ious}\n",
    "    val_history.append(val_dict)\n",
    "    \n",
    "    if tr_loss < best_val:\n",
    "        best_val = tr_loss\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "    \n",
    "    print(\"Epoch: {},\\nTraining: Loss={}, mIOU= {},\\\n",
    "          \\nValidation: Loss={}, mIOU={}\".format(\n",
    "        epoch,tr_dict['loss'], tr_dict['miou']\n",
    "        val_dict['loss'], val_dict['miou']))\n",
    "    \n",
    "f1 = open('training_log.pkl', 'rb')\n",
    "pickle.dump(train_history, f1)\n",
    "f1.close()\n",
    "\n",
    "f2 = open('validation_log.pkl', 'rb')\n",
    "pickle.dump(val_history, f2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
